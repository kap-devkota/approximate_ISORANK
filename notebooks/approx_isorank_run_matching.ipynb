{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Tests between Different Isorank Approximations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to use netalign package, go to the base folder \n",
    "# and run:\n",
    "#           python setup.py build; python setup.py install;\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from netalign.approx_isorank.io_utils import compute_adjacency, compute_pairs\n",
    "from netalign.approx_isorank.isorank_compute import compute_isorank, compute_greedy_assignment, pair_acc\n",
    "from netalign.approx_isorank.pair_evaluations import compute_edge_correctness, semantic_sim, symmetric_substructure, lccs\n",
    "from numpy.linalg import norm\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters:\n",
    "\n",
    "1. Net1 => Tab delimited file containing the first PPI network to be aligned\n",
    "2. Net2 => Tab delimited file containing the second PPI network to be aligned\n",
    "3. Rblast => Reciprocal blast tab-delimited file containing the sequence similarity score between proteins.\n",
    "4. Alpha => Isorank Parameter. Usually set to 0.7\n",
    "5. Niter => If R0 approximation, set this to 0, if R1 approximation, set this to 1. Else, set this to \n",
    "some value > 10 to get the original IsoRank matrix.\n",
    "6. Npairs => How many aligned pairs to output\n",
    "7. Annot1 => GOA annotation file for the first species\n",
    "8. Annot2 => GOA annotation file for the second species.\n",
    "\n",
    "*** Both the annotation files are obtained from the official GO website ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = \"../data/intact/bakers.s.tsv\"\n",
    "net2 = \"../data/intact/rat.s.tsv\"\n",
    "rblast = \"../data/intact/rat-bakers.tsv\"\n",
    "alpha = 0.7\n",
    "niters = [0, 1, 10]\n",
    "npairs = 1000\n",
    "annot1 = \"../data/go/bakers.output.mapping.gaf\"\n",
    "annot2 = \"../data/go/rat.output.mapping.gaf\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run IsoRank approximations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing adjacency matrix ...\n",
      "Getting the sequence similarity matrix\n",
      "      bakers   rat     score\n",
      "0       4976  2254  0.120443\n",
      "1         35  2254  0.123143\n",
      "2       3911  2254  0.088307\n",
      "3       6206  2254  0.066973\n",
      "4       3893  2254  0.045153\n",
      "...      ...   ...       ...\n",
      "8601    4619  9595  0.047313\n",
      "8602    5940  9595  0.039103\n",
      "8603    4934  9595  0.037213\n",
      "8604    6106  9595  0.048879\n",
      "8605    5304  4187  0.154739\n",
      "\n",
      "[8606 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(net1, sep = \"\\t\", header = None)\n",
    "df2 = pd.read_csv(net2, sep = \"\\t\", header = None)\n",
    "dpairs = pd.read_csv(rblast, sep = \"\\t\")\n",
    "\n",
    "\n",
    "org1 = net1.split(\"/\")[-1].split(\".\")[0] # gives \"bakers\"\n",
    "org2 = net2.split(\"/\")[-1].split(\".\")[0] # gives \"rat\"\n",
    "\n",
    "print(\"Computing adjacency matrix ...\")\n",
    "Af1, nA1 = compute_adjacency(df1)\n",
    "Af2, nA2 = compute_adjacency(df2)\n",
    "\n",
    "print(\"Getting the sequence similarity matrix\")\n",
    "E = compute_pairs(dpairs, nA1, nA2, org1, org2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the IsoRank matrices\n",
    "R0, R1, R2 = compute_isorank(Af1, \n",
    "                             Af2,\n",
    "                             E, \n",
    "                             alpha = alpha,\n",
    "                             maxiter = 5,\n",
    "                             get_R0 = True,\n",
    "                             get_R1 = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0033744466169843444, 0.00024736547389922654)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm0 = norm(R0 - R2)\n",
    "norm1 = norm(R1 - R2)\n",
    "norm0, norm1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing Greedy alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for R0...\n",
      "for R1...\n",
      "for R2...\n"
     ]
    }
   ],
   "source": [
    "print(\"for R0...\")\n",
    "pairs0 = compute_greedy_assignment(R0, npairs)\n",
    "print(\"for R1...\")\n",
    "pairs1 = compute_greedy_assignment(R1, npairs)\n",
    "print(\"for R2...\")\n",
    "pairs2 = compute_greedy_assignment(R2, npairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations\n",
    "\n",
    "1. Edge Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First index the edgelist by their indexes\n",
    "df1[0] = df1[0].apply(lambda x : nA1[x])\n",
    "df1[1] = df1[1].apply(lambda x : nA1[x])\n",
    "    \n",
    "df2[0] = df2[0].apply(lambda x : nA2[x])\n",
    "df2[1] = df2[1].apply(lambda x : nA2[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04032047941636269, 0.04758102395490841, 0.04894268491053488)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec0 = compute_edge_correctness(pairs0, df1, df2)\n",
    "ec1 = compute_edge_correctness(pairs1, df1, df2)\n",
    "ec2 = compute_edge_correctness(pairs2, df1, df2)\n",
    "ec0, ec1, ec2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Symmetric Substructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03357743422836995, 0.041219075520833336, 0.04225875743555849)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sstructure0 = symmetric_substructure(pairs0, df1, df2)\n",
    "sstructure1 = symmetric_substructure(pairs1, df1, df2)\n",
    "sstructure2 = symmetric_substructure(pairs2, df1, df2)\n",
    "\n",
    "sstructure0, sstructure1, sstructure2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. LCCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 545, 552)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc0 = lccs(pairs0, df1, df2)\n",
    "lc1 = lccs(pairs1, df1, df2)\n",
    "lc2 = lccs(pairs2, df1, df2)\n",
    "\n",
    "lc0, lc1, lc2    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Functional Similarities\n",
    "\n",
    "In order to run FC experiments, convert the pairs and the pandas dataframes to the Gene namespace.\n",
    "This code section requires an additional package `goatools`. It can be installed by using the command:\n",
    "\n",
    "```\n",
    "pip install goatools\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute reverse dictionaries\n",
    "rnA1 = {v: k for k, v in nA1.items()}\n",
    "rnA2 = {v: k for k, v in nA2.items()}\n",
    "\n",
    "df1.iloc[:, 0] = df1.iloc[:, 0].apply(lambda x: rnA1[x])\n",
    "df1.iloc[:, 1] = df1.iloc[:, 1].apply(lambda x: rnA1[x])\n",
    "\n",
    "\n",
    "df2.iloc[:, 0] = df2.iloc[:, 0].apply(lambda x: rnA2[x])\n",
    "df2.iloc[:, 1] = df2.iloc[:, 1].apply(lambda x: rnA2[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For R0:\n",
      "  EXISTS: ../data/go/go-basic.obo\n",
      "../data/go/go-basic.obo: fmt(1.2) rel(2022-12-04) 46,763 Terms; optional_attrs(relationship)\n",
      "\t For GO=molecular_function, FC = 0.49946807698617535\n",
      "  EXISTS: ../data/go/go-basic.obo\n",
      "../data/go/go-basic.obo: fmt(1.2) rel(2022-12-04) 46,763 Terms; optional_attrs(relationship)\n",
      "\t For GO=biological_process, FC = 0.22385897901631305\n",
      "  EXISTS: ../data/go/go-basic.obo\n",
      "../data/go/go-basic.obo: fmt(1.2) rel(2022-12-04) 46,763 Terms; optional_attrs(relationship)\n",
      "\t For GO=cellular_component, FC = 0.4195773878742229\n",
      "For R1:\n",
      "  EXISTS: ../data/go/go-basic.obo\n",
      "../data/go/go-basic.obo: fmt(1.2) rel(2022-12-04) 46,763 Terms; optional_attrs(relationship)\n",
      "\t For GO=molecular_function, FC = 0.4551539284983664\n",
      "  EXISTS: ../data/go/go-basic.obo\n",
      "../data/go/go-basic.obo: fmt(1.2) rel(2022-12-04) 46,763 Terms; optional_attrs(relationship)\n",
      "\t For GO=biological_process, FC = 0.20266467894311752\n",
      "  EXISTS: ../data/go/go-basic.obo\n",
      "../data/go/go-basic.obo: fmt(1.2) rel(2022-12-04) 46,763 Terms; optional_attrs(relationship)\n",
      "\t For GO=cellular_component, FC = 0.3946772984368074\n",
      "For R2:\n",
      "  EXISTS: ../data/go/go-basic.obo\n",
      "../data/go/go-basic.obo: fmt(1.2) rel(2022-12-04) 46,763 Terms; optional_attrs(relationship)\n",
      "\t For GO=molecular_function, FC = 0.46105314993751934\n",
      "  EXISTS: ../data/go/go-basic.obo\n",
      "../data/go/go-basic.obo: fmt(1.2) rel(2022-12-04) 46,763 Terms; optional_attrs(relationship)\n",
      "\t For GO=biological_process, FC = 0.2032075583565407\n",
      "  EXISTS: ../data/go/go-basic.obo\n",
      "../data/go/go-basic.obo: fmt(1.2) rel(2022-12-04) 46,763 Terms; optional_attrs(relationship)\n",
      "\t For GO=cellular_component, FC = 0.39619736465914396\n"
     ]
    }
   ],
   "source": [
    "FC = {}\n",
    "for name, pair in [(\"R0\", pairs0), (\"R1\", pairs1), (\"R2\", pairs2)]:\n",
    "    print(f\"For {name}:\")\n",
    "    pair_ = [(rnA1[p], rnA2[q]) for p, q in pair]\n",
    "    for gotype in [\"molecular_function\", \"biological_process\", \"cellular_component\"]:\n",
    "        fc = semantic_sim(pair_, df1, df2,\n",
    "                        obofile = \"../data/go/go-basic.obo\",\n",
    "                        annot1file=annot1,\n",
    "                        annot2file = annot2,\n",
    "                        type = gotype)\n",
    "        print(f\"\\t For GO={gotype}, FC = {fc}\")\n",
    "        FC[f\"FC-{gotype}({name})\"] = fc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
